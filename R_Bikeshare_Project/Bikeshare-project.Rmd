---
title: "Bikeshare project"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

This is the capstone project from the Google Data Analyst Certificate.

I downloaded bike-share data from here: <https://divvy-tripdata.s3.amazonaws.com/index.html>

The data is published under this license: <https://ride.divvybikes.com/data-license-agreement>




Description of business task:

The goal of the project is to answer the following questions to help the marketing team sell more annual subscriptions for the company

Three questions will guide the future marketing program:
1. How do annual members and casual riders use Cyclistic bikes differently?
2. Why would casual riders buy Cyclistic annual memberships?
3. How can Cyclistic use digital media to influence casual riders to become members?


Load libraries:
```{r}
require(tidyverse)  
require(lubridate)  
require(ggplot2)  
require(data.table)
require(scales)
```

Import trip data:
```{r}
data_2021_08 <- read_csv('Original_Data/202108-divvy-tripdata.csv')
data_2021_09 <- read_csv('Original_Data/202109-divvy-tripdata.csv')
data_2021_10 <- read_csv('Original_Data/202110-divvy-tripdata.csv')
data_2021_11 <- read_csv('Original_Data/202111-divvy-tripdata.csv')
data_2021_12 <- read_csv('Original_Data/202112-divvy-tripdata.csv')
data_2022_01 <- read_csv('Original_Data/202201-divvy-tripdata.csv')
data_2022_02 <- read_csv('Original_Data/202202-divvy-tripdata.csv')
data_2022_03 <- read_csv('Original_Data/202203-divvy-tripdata.csv')
data_2022_04 <- read_csv('Original_Data/202204-divvy-tripdata.csv')
data_2022_05 <- read_csv('Original_Data/202205-divvy-tripdata.csv')
data_2022_06 <- read_csv('Original_Data/202206-divvy-tripdata.csv')
data_2022_07 <- read_csv('Original_Data/202207-divvy-tripdata.csv')
```

Bind rows into one dataframe:
```{r}
trip_data <- rbind(data_2021_08, data_2021_09, data_2021_10,
                          data_2021_11, data_2021_12, data_2022_01,
                          data_2022_02, data_2022_03, data_2022_04,
                          data_2022_05, data_2022_06, data_2022_07)
```

Check how many missing values in each column:
```{r}
na_counts <- colSums(is.na(trip_data))
print(na_counts)
```

Take a closer look at the columns where data is missing
```{r}
trip_data[!complete.cases(trip_data),]
```

It appears that in the rows where the start/end_station is missing, the
corresponding coordinates are precise to only 2 decimal places.
This means that there is no reliable way to extrapolate missing data, so it must
be removed.

Remove rows with missing data, sort chronologically:
```{r}
trip_data_2 <- drop_na(trip_data)
trip_data_2 <- trip_data_2[order(trip_data_2$started_at),]

cat("Percentage or rows lost:",
          100-round(nrow(trip_data_2)*100/nrow(trip_data)))
```

Now let's take a look at the rideable_type column:
```{r}
rideable_list = unique(as.list(trip_data_2$rideable_type))
print(rideable_list)
```

why are there docked bikes in the trip data?
```{r}
docked_df <- trip_data_2[(trip_data_2$rideable_type=="docked_bike"),]
docked_df

```
It seems like there are no members in this dataframe.
This would be just another reason to confirm that these are not real rides.
These "rides" seem to be generated by the company moving bikes to balance the
number of bikes at each station.

Let's confirm:
```{r}
print(unique(as.list(docked_df$member_casual)))
```
Let's remove these rows

```{r}
trip_data_3 <- trip_data_2[!(trip_data_2$rideable_type=="docked_bike"),]
trip_data_3
```



check for duplicate rides

```{r}
print(length(unique(trip_data_3$ride_id)))
print(nrow(trip_data_3))
```



count number of distinct station names and ids

```{r}
station_list = as.list(cbind(trip_data_3$start_station_name,
                             trip_data_3$end_station_name))
id_list = as.list(cbind(trip_data_3$start_station_name,
                        trip_data_3$end_station_name))


n_station_names <- length(unique(station_list))
n_station_ids <- length(unique(id_list))

cat("Unique station names: ", n_station_names, '\n')
cat("Unique station ids: ", n_station_ids)
```

It seems like there might be more stations than there are supposed to be.
In the challenge description, it was stated that there are 692 stations.
This could be because the public racks are not counted.

I went to the Divvy website and found a dataset that contains the station info.
I will use this to confirm the number of stations.

```{r}
station_data <- read_csv('Original_Data/Divvy_Bicycle_Stations.csv')
```
1419 rows - this is close to 1368 - the number of stations in my dataset.
This confirms that the number of stations is not completely off as I first
thought when compared to the 692 figure in the challenge description.



Find number of trips that start/end at each station:
```{r}
station_freq_table <- table(rbind(trip_data_3$start_station_name,
                                  trip_data_3$end_station_name))
station_freq_table <- as.data.frame(station_freq_table)
station_freq_table <- rename(station_freq_table, start_station_name = Var1)

#Sort by Frequency:
station_freq_table <- station_freq_table %>% arrange(desc(Freq))
station_freq_table
```



Add columns for trip length, day of the week, and month

```{r}
#add column for trip length (in seconds)
trip_data_3$trip_length <- trip_data_3$ended_at-trip_data_3$started_at
trip_data_3$trip_length <- as.numeric(as.character(trip_data_3$trip_length))

#add column for day of the week
trip_data_3$weekday <- format(trip_data_3$started_at, "%A")

#add column for month
trip_data_3$month <- factor(format(trip_data_3$started_at, "%b"), levels = month.abb)
trip_data_3 
```

remove trips with negative length

```{r}
trip_data_4 <- trip_data_3[(trip_data_3$trip_length > 0),]
cat("Number of rows removed: ", nrow(trip_data_3)-nrow(trip_data_4))
```



Now after I have cleaned this data, it is time to analyse it.

Frequency of Trips by Duration (only trips less than 1h for better visibility)

```{r}
ggplot(data=trip_data_4 %>% filter(trip_length <= 3600), aes(x=trip_length/60)) +
  geom_histogram(bins=60) +
  facet_wrap(~member_casual, nrow=1) +
  xlab("Trip Duration (Minutes)") +
  ylab("Number of Trips (1000s)") +
  scale_y_continuous(labels = unit_format(unit="K", scale = 1e-3))+
  ggtitle("Frequency of Trips by Duration")
```

Here we see that casual members take longer trips but members take more trips.

Let's get the actual median and mean length of trips done by the two types of users.

```{r}
aggregate(trip_data_4$trip_length ~ trip_data_4$member_casual, FUN = mean)
aggregate(trip_data_4$trip_length ~ trip_data_4$member_casual, FUN = median)
aggregate(trip_data_4$trip_length ~ trip_data_4$member_casual, FUN = min)
aggregate(trip_data_4$trip_length ~ trip_data_4$member_casual, FUN = max)
aggregate(trip_data_4$trip_length ~ trip_data_4$member_casual, FUN = sum)
```
Here we see that the longest trip was 25h long.
Extremely long trips like this make the mean less relevant and the median should be used instead.

The median trip lengths are 842s (14:02) for casual users
                        and 550s (9:10) for members


Since members make shorter, but more frequent trips, let's see if they are more
consistent throughout the months and weekdays


Let's visualize the number of rides by rider type
#already did this - compare to previous solution
```{r}

trip_data_4 %>% 
 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = number_of_rides/1000, fill = member_casual)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = round(number_of_rides/1000)), vjust = 1.5, position = position_dodge(.9), colour = "white")+
  labs(y = "Number of Trips (1000s)", x="Day of the Week", fill = "Member or Casual Rider") +
  ggtitle("Number of Trips by Day of the Week") +
  scale_x_discrete(limits = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
```

Let's create a visualization for median duration by weekday

```{r}
trip_data_4 %>% 
 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,median_duration = median(trip_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = median_duration/60, fill = member_casual)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = round(median_duration/60)), vjust = 1.5, position = position_dodge(.9), colour = "white")+
  labs(y = "Trip Duration (Minutes)", x="Day of the Week", fill = "Member or Casual Rider") +
  ggtitle("Median Trip Duration by Day of the Week") +
  scale_x_discrete(limits = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
```




```{r}
trip_data_4 %>% 
 
  group_by(member_casual, month) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(trip_length)) %>% 
  arrange(member_casual, month)  %>% 
  ggplot(aes(x = month, y = number_of_rides/1000, fill = member_casual)) +
  geom_col(position = "dodge")+
  ggtitle("Number of Trips by Month") +
  labs(y = "Number of Trips (1000s)", x="Month", fill = "Member or Casual Rider") +
  geom_text(aes(label = round(number_of_rides/1000)), vjust = 1.5, position = position_dodge(.9), size = 2.75, colour = "white")
```



```{r}
trip_data_4 %>% 
 
  group_by(member_casual, month) %>% 
  summarise(number_of_rides = n()
            ,median_duration = median(trip_length)) %>% 
  arrange(member_casual, month)  %>% 
  ggplot(aes(x = month, y = median_duration/60, fill = member_casual)) +
  geom_col(position = "dodge") +
  ggtitle("Median Trip Duration by Month") +
  labs(y = "Trip Duration (Minutes)", x="Month", fill = "Member or Casual Rider") +
  geom_text(aes(label = round(median_duration/60)), vjust = 1.5, position = position_dodge(.9), size = 2.75, colour = "white")
  
```

